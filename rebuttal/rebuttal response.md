We appreciate the reviewers’ feedback. We have included all detailed explanations of the study method in the [online appendix](https://github.com/Anonymousauthor2024/Supplementary-documentation) and have revised all presentation issues according to the four reviewers’ feedback as well (see [updated version](https://github.com/Anonymousauthor2024/Supplementary-documentation/tree/main/rebuttal)).

### ReviewerA

We greatly appreciate your feedback and have made the following revisions based on your suggestions:

1. Revised the related work section by providing more details on prior findings and moved all RQs to the end.
2. Revised the method and findings sections to clarify how the methods address our RQs.
3. Added details in the Appendix about the case study, including information sources, audit firm information, and results of website information disclosure reviews.
4. Provided detailed information in the Appendix about validating the GPT-4 analysis.
5. Standardized the reporting of interviewee numbers using absolute values.
6. Added more citations in the design implications section regarding reputation enhancement and removed implications related to Web2.

Additionally, we have addressed your specific concerns as follows:

**Clarification of the Relationship Between Methods and Findings**:  
To provide a clearer understanding of the relationships between methods, findings, and RQs, we have included both a figure (showing the relationship between methods and RQs) and a table (summarizing the connections between methods, findings, and RQs). We have also provided a direct explanation in the [online document](https://github.com/Anonymousauthor2024/Supplementary-documentation/blob/main/Research%20Method%2C%20Research%20Questions%2C%20and%20Findings%20Relationship.md).

Specifically:
1. **Case Study** includes two key steps:  
   - **Observing audit information of audited projects**.
   - **Reviewing audit firms' homepage information disclosures**.  
     - This provides **empirical validation** for our interview findings.

   Together, these steps form the **interaction framework** for Web3 auditing, which serves as the foundation for the **interview design**.

2. **Interviews** serve as the **primary research method**, uncovering most of the findings.

3. **Reddit Analysis** supplements and cross-validates the interview findings:  
   - **Qualitative analysis** through **thematic categorization** supports the interview findings.
   - **Quantitative analysis**, using **sentiment analysis**, captures online community attitudes.

**Consideration of Recall Rate**: We acknowledge the previous limitation of not considering the recall rate and will update the limitations section. After re-evaluating, we found that the recall rates were consistently above 80%.


### ReviewerB

**Rebuttal to Solution Complexity**: We acknowledge that the widespread adoption of our design implications may take time. However, as we are collaborating with leading auditing firms and providing practical recommendations, some of our suggestions have already been proven feasible, such as [CertiK’s implementation](https://skynet.certik.com/) of data change logs and easily accessible explanations for security metrics calculations.

**Clarification for Sample Size**: We would like to clarify that our sample size **aligns with** the interview sample sizes reported in prior studies related to **Web3 usable security in top conferences**, published in IEEE S&P [1], USENIX Security [2], and CHI [3], which included 13, 14, and 21 participants, respectively. Qualitative research can derive unique value from such sample sizes. Additionally, we combined these interviews with community discussions from Reddit, involving over 2000 users, which further enhances the generalizability of our findings.

### ReviewerC

**Comparison with Privacy Policy Research**: 
We acknowledge your insightful comment on privacy policy research in conveying information to users and recognize its similarities with Web3 auditing. We have updated this comparison in the Appendix. Specifically, privacy policies, as complex terminology, impact user comprehension. Measures from privacy policy research, such as simplifying language and using icons, provide valuable insights for improving information delivery in Web3 audits.

However, there are significant differences between the two in terms of information delivery, user initiative, disclosure methods, authority, and educational roles. These differences lead to varying focus points in studying user perceptions and require different design recommendations. We have provided an easily accessible comparison version in our [online document](https://github.com/Anonymousauthor2024/Supplementary-documentation/blob/main/Discussion%3A%20Comparison%20with%20Privacy%20Policy%20Research.md). 


**Removal Web2 Design Implication**: We acknowledge the significant differences between the Web2 and Web3 ecosystems and appreciate your suggestion to remove this content. It has been removed in the updated version.


### ReviewerD
We sincerely appreciate your feedback and have made the following brief clarifications, which are reflected in the revised version:

**Explanation for Interviewee Knowing Price Information**:  
10% of interviewees learned about price information from friends who had received audit services. The price ranges they mentioned varied significantly, from several thousand to tens of thousands of dollars.

**Experience Explanation Regarding Demographics**:  
Our limitations section acknowledges the shortcomings related to users with rich experience, and we will address this in future studies.

**Explanation for Distinct Self-Introduction**:  
This refers to the difference in self-introduction, where the company emphasized its contributions to the blockchain industry in China—such as industry benchmarks and government-issued titles—in the Chinese version, while these details were not mentioned in the English version.

**Providing Online Documentation**:  
Your suggestion is highly valuable. We have made all relevant content available in the appendix for easier access by readers.



[1]Guthoff C et al. Perceptions of distributed ledger technology key management-an interview study with finance professionals[C]//2023 IEEE Symposium on Security and Privacy (SP). 
[2]Liu M et al. I Experienced More than 10 {DeFi} Scams: On {DeFi} Users' Perception of Security Breaches and Countermeasures[C]//33rd USENIX Security Symposium (USENIX Security 24). 
[3] Si J J et al.. Understanding User-Perceived Security Risks and Mitigation Strategies in the Web3 Ecosystem[C]//Proceedings of the CHI Conference on Human Factors in Computing Systems.


